{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五章 深层学习模型\n",
    "\n",
    "本章依赖的类库有：\n",
    "\n",
    "- numpy 快速操作结构数组的工具\n",
    "- keras 二次封装的深度学习库\n",
    "- tensorflow 深度学习库\n",
    "- caffe 深度学习库\n",
    "\n",
    "python类库安装教程见实体书附录A，深度学习库安装教程见实体书附录B，每个小节可以独立运行。\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 解密生物智能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验一：大脑的材料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看：一只猫在卖萌!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# 保存当前重定向\n",
    "default_stdout = sys.stdout\n",
    "default_stderr = sys.stderr\n",
    "reload(sys)\n",
    "# 修改默认的ascii编码\n",
    "sys.setdefaultencoding('utf-8')\n",
    "# 恢复重定向\n",
    "sys.stdout = default_stdout\n",
    "sys.stderr = default_stderr\n",
    "\n",
    "\"\"\"由五感输入的刺激信号。对应行为：看 听 闻 触 嗅\"\"\"\n",
    "d_signals = {\n",
    "    '视觉信号': '看',\n",
    "    '听觉信号': '听'\n",
    "}\n",
    "\n",
    "\n",
    "class Neuron(object):\n",
    "    \"\"\"神经元\"\"\"\n",
    "\n",
    "    def __init__(self, signal_type):\n",
    "        # 神经元拥有处理某种类型信号的能力\n",
    "        self.signal_type = signal_type\n",
    "\n",
    "    def spike(self, x):\n",
    "        \"\"\"神经元激活函数。输入某种类型的刺激信号，有可能激活神经元响应刺激\"\"\"\n",
    "        if x.signal_type == self.signal_type:\n",
    "            return d_signals[self.signal_type] + '：' + x.data\n",
    "        else:\n",
    "            return d_signals[self.signal_type] + '：' + '什么都没' + \\\n",
    "                   d_signals[self.signal_type] + '到'\n",
    "\n",
    "\n",
    "class SignalInput(object):\n",
    "    \"\"\"输入信号\"\"\"\n",
    "    \n",
    "    def __init__(self, signal_type, data):\n",
    "        self.signal_type = signal_type\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "x = SignalInput('视觉信号', '一只猫在卖萌!')\n",
    "print(Neuron('视觉信号').spike(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验二：探索脑皮层的功能区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视觉皮层在处理：一只猫在卖萌!\n",
      "听觉皮层在处理：猫咪在喵喵叫!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class VisualBrain:\n",
    "    \"\"\"视觉皮层\"\"\"\n",
    "\n",
    "    def __init__(self, num):\n",
    "        self.neurons = [Neuron('视觉信号') for i in range(num)]\n",
    "\n",
    "    def process(self, x):\n",
    "        \"\"\"处理信号\"\"\"\n",
    "        print('视觉皮层在处理：' + x.data)\n",
    "\n",
    "\n",
    "class AuditoryBrain:\n",
    "    \"\"\"听觉皮层\"\"\"\n",
    "\n",
    "    def __init__(self, num):\n",
    "        self.neurons = [Neuron('听觉信号') for i in range(num)]\n",
    "\n",
    "    def process(self, x):\n",
    "        \"\"\"处理信号\"\"\"\n",
    "        print('听觉皮层在处理：' + x.data)\n",
    "\n",
    "\n",
    "class Brain:\n",
    "    \"\"\"脑皮层\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # 分配神经元数量，人脑更依赖视觉输入获得信息，所以视觉神经元数量应该更多\n",
    "        self.visual_model = VisualBrain(3000)\n",
    "        self.auditory_model = AuditoryBrain(1000)\n",
    "\n",
    "    def process(self, x):\n",
    "        \"\"\"根据不同的传入信号，传递给不同的皮层组织处理\"\"\"\n",
    "        result = {\n",
    "            '视觉信号': lambda x: self.visual_model.process(x),\n",
    "            '听觉信号': lambda x: self.auditory_model.process(x),\n",
    "        }[x.signal_type](x)\n",
    "\n",
    "\n",
    "brain = Brain()\n",
    "x_see = SignalInput('视觉信号', '一只猫在卖萌!')\n",
    "x_hear = SignalInput('听觉信号', '猫咪在喵喵叫!')\n",
    "\n",
    "brain.process(x_see)\n",
    "brain.process(x_hear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验三：不同的皮层组织——区别在于函数算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VisualBrain:\n",
    "    \"\"\"视觉皮层\"\"\"\n",
    "\n",
    "    def __init__(self, num):\n",
    "        self.neurons = [Neuron('视觉信号') for i in range(num)]\n",
    "\n",
    "    def process(self, x):\n",
    "        \"\"\"处理信号\"\"\"\n",
    "        print('输入' + x.signal_type + '：' + x.data)\n",
    "        reactions = [neuron.spike(x) for neuron in self.neurons]\n",
    "        # 一群神经元集体响应投票，打印票数最高的响应\n",
    "        top_reaction = Counter(reactions).most_common(1)\n",
    "        print('>> 我在用眼睛（视觉皮层）' + top_reaction[0][0])\n",
    "\n",
    "\n",
    "class AuditoryBrain:\n",
    "    \"\"\"听觉皮层\"\"\"\n",
    "\n",
    "    def __init__(self, num):\n",
    "        self.neurons = [Neuron('听觉信号') for i in range(num)]\n",
    "\n",
    "    def process(self, x):\n",
    "        \"\"\"处理信号\"\"\"\n",
    "        print('输入' + x.signal_type + '：' + x.data)\n",
    "        reactions = [neuron.spike(x) for neuron in self.neurons]\n",
    "        # 一群神经元集体响应投票，打印票数最高的响应\n",
    "        top_reaction = Counter(reactions).most_common(1)\n",
    "        print('>> 我在用耳朵（听觉皮层）' + top_reaction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用眼睛（视觉皮层）看：一只猫在卖萌!\n",
      "输入听觉信号：猫咪在喵喵叫!\n",
      ">> 我在用耳朵（听觉皮层）听：猫咪在喵喵叫!\n"
     ]
    }
   ],
   "source": [
    "brain = Brain()\n",
    "x_see = SignalInput('视觉信号', '一只猫在卖萌!')\n",
    "x_hear = SignalInput('听觉信号', '猫咪在喵喵叫!')\n",
    "\n",
    "brain.process(x_see)\n",
    "brain.process(x_hear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入听觉信号：猫咪在喵喵叫!\n",
      ">> 我在用眼睛（视觉皮层）看：什么都没看到\n"
     ]
    }
   ],
   "source": [
    "brain.auditory_model.process(x_see)\n",
    "brain.visual_model.process(x_hear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验四：可替换的皮层模块——神经元组成的学习模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Neuron(object):\n",
    "    \"\"\"神经元\"\"\"\n",
    "\n",
    "    def __init__(self, signal_type):\n",
    "        # 神经元拥有处理某种类型信号的能力\n",
    "        self.signal_type = signal_type\n",
    "\n",
    "    def spike(self, x):\n",
    "        \"\"\"输入某种类型的刺激信号，有可能激活神经元响应刺激\"\"\"\n",
    "        # 假设神经元有1%的概率被训练\n",
    "        if random.random() < 0.01:\n",
    "            self.signal_type = x.signal_type\n",
    "        if x.signal_type == self.signal_type:\n",
    "            return d_signals[self.signal_type] + '：' + x.data\n",
    "        else:\n",
    "            return d_signals[self.signal_type] + '：' + '什么都没' + \\\n",
    "                   d_signals[self.signal_type] + '到'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）听：什么都没听到\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n",
      "输入视觉信号：一只猫在卖萌!\n",
      ">> 我在用耳朵（听觉皮层）看：一只猫在卖萌!\n"
     ]
    }
   ],
   "source": [
    "brain = Brain()\n",
    "for i in range(100):\n",
    "    brain.auditory_model.process(x_see)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 DNN神经网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑分类：一层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 128 # 梯度下降批数据量\n",
    "nb_classes = 10 # 类别\n",
    "nb_epoch = 10 # 循环训练集次数\n",
    "img_size = 28 * 28 # 输入图片大小\n",
    "\n",
    "# 加载数据，已执行shuffle-split（训练-测试集随机分割）\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 以Tensorflow为后端，归一化输入数据，生成图片向量\n",
    "X_train = X_train.reshape(y_train.shape[0], img_size).astype('float32') / 255\n",
    "X_test = X_test.reshape(y_test.shape[0], img_size).astype('float32') / 255\n",
    "\n",
    "# One-Hot编码标签，将如[3,2,...] 编码成[[0,0,0,1,0,0,0,0,0,0], [0,0,1,0,0,0,0,0,0,0],...]\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 增加Hidden Layer（隐层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.3297 - acc: 0.9098 - val_loss: 0.1880 - val_acc: 0.9442\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.1549 - acc: 0.9553 - val_loss: 0.1377 - val_acc: 0.9592\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s - loss: 0.1123 - acc: 0.9678 - val_loss: 0.1137 - val_acc: 0.9654\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.0878 - acc: 0.9742 - val_loss: 0.0966 - val_acc: 0.9710\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s - loss: 0.0721 - acc: 0.9788 - val_loss: 0.0881 - val_acc: 0.9738\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s - loss: 0.0612 - acc: 0.9819 - val_loss: 0.0838 - val_acc: 0.9745\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s - loss: 0.0521 - acc: 0.9851 - val_loss: 0.0814 - val_acc: 0.9764\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.0447 - acc: 0.9871 - val_loss: 0.0804 - val_acc: 0.9757\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.0387 - acc: 0.9891 - val_loss: 0.0796 - val_acc: 0.9769\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s - loss: 0.0342 - acc: 0.9899 - val_loss: 0.0800 - val_acc: 0.9768\n",
      "accuracy: 0.9768\n"
     ]
    }
   ],
   "source": [
    "# 创建模型，增加一层包含128个神经元节点的隐层\n",
    "model = Sequential([\n",
    "Dense(128, input_shape=(img_size,), activation='relu'),\n",
    "Dense(10, input_shape=(128,), activation='softmax'),\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 训练\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# 测试\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('accuracy: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELU激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x * (x > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 典型的DNN深层网络模型：MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras实现MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "nb_classes = 10 # 类别\n",
    "img_size = 28 * 28 # 输入图片大小\n",
    "\n",
    "# 加载数据，已执行shuffle-split（训练-测试集随机分割）\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 以Tensorflow为后端，归一化输入数据，生成图片向量\n",
    "X_train = X_train.reshape(y_train.shape[0], img_size).astype('float32') / 255\n",
    "X_test = X_test.reshape(y_test.shape[0], img_size).astype('float32') / 255\n",
    "\n",
    "# One-Hot编码标签，将如[3,2,...] 编码成[[0,0,0,1,0,0,0,0,0,0], [0,0,1,0,0,0,0,0,0,0],...]\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_1 (Dense)                  (None, 512)           401920      dense_input_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512)           0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 512)           262656      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 512)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512)           0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            5130        dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 创建模型，增加一层包含128个神经元节点的隐层；Dense默认activation为linear线性\n",
    "model = Sequential([\n",
    "Dense(512, input_shape=(img_size,)),\n",
    "Activation('relu'),\n",
    "Dropout(0.2),\n",
    "Dense(512, input_shape=(512,)),\n",
    "Activation('relu'),\n",
    "Dropout(0.2),\n",
    "Dense(10, input_shape=(512,), activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 13s - loss: 0.2446 - acc: 0.9239 - val_loss: 0.1211 - val_acc: 0.9631\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s - loss: 0.1025 - acc: 0.9688 - val_loss: 0.0796 - val_acc: 0.9750\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 15s - loss: 0.0758 - acc: 0.9776 - val_loss: 0.0768 - val_acc: 0.9774\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 15s - loss: 0.0609 - acc: 0.9820 - val_loss: 0.1066 - val_acc: 0.9678\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 14s - loss: 0.0517 - acc: 0.9845 - val_loss: 0.0878 - val_acc: 0.9782\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s - loss: 0.0441 - acc: 0.9866 - val_loss: 0.0770 - val_acc: 0.9822\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 14s - loss: 0.0403 - acc: 0.9879 - val_loss: 0.0752 - val_acc: 0.9821\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 14s - loss: 0.0362 - acc: 0.9892 - val_loss: 0.0769 - val_acc: 0.9831\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s - loss: 0.0310 - acc: 0.9909 - val_loss: 0.0817 - val_acc: 0.9840\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 15s - loss: 0.0295 - acc: 0.9914 - val_loss: 0.0842 - val_acc: 0.9827\n",
      "accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # 梯度下降批数据量\n",
    "nb_epoch = 10 # 循环训练集次数\n",
    "\n",
    "# 训练\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# 测试\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('accuracy: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Caffe实现MLP\n",
    "\n",
    "\n",
    "### 搭建MLP\n",
    "\n",
    "见第五章目录下文件。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
